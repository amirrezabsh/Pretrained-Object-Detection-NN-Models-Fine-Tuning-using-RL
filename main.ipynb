{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8f97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: stable-baselines3 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: ultralytics in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (8.3.228)\n",
      "Requirement already satisfied: gym in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (2.2.6)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from stable-baselines3) (1.2.2)\n",
      "Requirement already satisfied: cloudpickle in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from stable-baselines3) (3.1.2)\n",
      "Requirement already satisfied: pandas in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from stable-baselines3) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from stable-baselines3) (3.10.7)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: psutil in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (7.1.3)\n",
      "Requirement already satisfied: polars in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from gym) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from pandas->stable-baselines3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from pandas->stable-baselines3) (2025.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in d:\\msc\\payannameh\\pretrained object detection nn models fine-tuning using rl\\source code\\.venv\\lib\\site-packages (from polars->ultralytics) (1.35.2)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbbefd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 503: Service Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_custom_dataset(IMAGE_DIR, LABEL_DIR, annotation_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo_txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, limit\u001b[38;5;241m=\u001b[39mDATA_LIMIT)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_pascal_voc2007\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mVOC_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_LIMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m env \u001b[38;5;241m=\u001b[39m ThresholdRefinementEnv(dataset)\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n",
      "File \u001b[1;32md:\\MSc\\PayanNameh\\Pretrained Object Detection NN Models Fine-Tuning using RL\\Source Code\\utility\\dataset.py:248\u001b[0m, in \u001b[0;36mload_pascal_voc2007\u001b[1;34m(root, image_set, limit, download)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_exists \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_download:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPascal VOC 2007 not found under \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Set download=True to fetch it automatically.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m     )\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVOCDetectionDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2007\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshould_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MSc\\PayanNameh\\Pretrained Object Detection NN Models Fine-Tuning using RL\\Source Code\\utility\\dataset.py:145\u001b[0m, in \u001b[0;36mVOCDetectionDataset.__init__\u001b[1;34m(self, root, image_set, year, download, limit)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m VOCDetection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision is required for VOC datasets. Install torchvision to continue.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mVOCDetection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit \u001b[38;5;241m=\u001b[39m limit\n",
      "File \u001b[1;32md:\\MSc\\PayanNameh\\Pretrained Object Detection NN Models Fine-Tuning using RL\\Source Code\\.venv\\lib\\site-packages\\torchvision\\datasets\\voc.py:98\u001b[0m, in \u001b[0;36m_VOCBase.__init__\u001b[1;34m(self, root, year, image_set, download, transform, target_transform, transforms)\u001b[0m\n\u001b[0;32m     95\u001b[0m voc_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, base_dir)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 98\u001b[0m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(voc_root):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\MSc\\PayanNameh\\Pretrained Object Detection NN Models Fine-Tuning using RL\\Source Code\\.venv\\lib\\site-packages\\torchvision\\datasets\\utils.py:388\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    386\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 388\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    391\u001b[0m extract_archive(archive, extract_root, remove_finished)\n",
      "File \u001b[1;32md:\\MSc\\PayanNameh\\Pretrained Object Detection NN Models Fine-Tuning using RL\\Source Code\\.venv\\lib\\site-packages\\torchvision\\datasets\\utils.py:118\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    115\u001b[0m     _download_file_from_remote_location(fpath, url)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# expand redirect chain if needed\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43m_get_redirect_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_redirect_hops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# check if file is located on Google Drive\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     file_id \u001b[38;5;241m=\u001b[39m _get_google_drive_file_id(url)\n",
      "File \u001b[1;32md:\\MSc\\PayanNameh\\Pretrained Object Detection NN Models Fine-Tuning using RL\\Source Code\\.venv\\lib\\site-packages\\torchvision\\datasets\\utils.py:63\u001b[0m, in \u001b[0;36m_get_redirect_url\u001b[1;34m(url, max_hops)\u001b[0m\n\u001b[0;32m     60\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT}\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_hops \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m==\u001b[39m url \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 503: Service Unavailable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from stable_baselines3 import PPO\n",
    "from envionments.threshold_refinement import ThresholdRefinementEnv\n",
    "from utility.dataset import load_pascal_voc2007, load_custom_dataset\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "VOC_ROOT = os.getenv(\"VOC_ROOT\", \"data/voc\")\n",
    "IMAGE_DIR = os.getenv(\"IMAGE_DIR\")\n",
    "LABEL_DIR = os.getenv(\"LABEL_DIR\")\n",
    "DATA_LIMIT = int(os.getenv(\"RL_DATA_LIMIT\", \"500\"))\n",
    "TOTAL_TIMESTEPS = int(os.getenv(\"RL_TOTAL_TIMESTEPS\", \"20000\"))\n",
    "LEARNING_RATE = float(os.getenv(\"RL_LEARNING_RATE\", \"3e-4\"))\n",
    "\n",
    "if IMAGE_DIR and LABEL_DIR:\n",
    "    dataset = load_custom_dataset(IMAGE_DIR, LABEL_DIR, annotation_format=\"yolo_txt\", limit=DATA_LIMIT)\n",
    "else:\n",
    "    dataset = load_pascal_voc2007(\n",
    "        VOC_ROOT, image_set=\"trainval\", limit=DATA_LIMIT, download=True\n",
    "    )\n",
    "\n",
    "env = ThresholdRefinementEnv(dataset)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=LEARNING_RATE, n_steps=512)\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
    "\n",
    "model.save(\"rl_threshold_tuner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from utility.evaluation import evaluate_policy, summarize_stats, plot_threshold_trajectories\n",
    "\n",
    "load_dotenv()\n",
    "EVAL_EPISODES = int(os.getenv(\"RL_EVAL_EPISODES\", \"5\"))\n",
    "\n",
    "stats = evaluate_policy(model, dataset, episodes=EVAL_EPISODES)\n",
    "summary = summarize_stats(stats)\n",
    "print(summary)\n",
    "\n",
    "plot_threshold_trajectories(stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
